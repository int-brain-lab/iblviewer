{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting IBLViewer...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "129a32b328a0490f9dab296e6b0073d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ViewInteractiveWidget(height=1200, layout=Layout(height='auto', width='100%'), width=1200)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os, sys\n",
    "sys.path.append(os.path.abspath('../'))\n",
    "# Lines above only for local testing by developers\n",
    "from iblviewer.atlas_controller import AtlasController\n",
    "\n",
    "controller = AtlasController()\n",
    "controller.initialize(resolution=25, embed_ui=True, jupyter=True, render=True)\n",
    "# Do not leave multi-line comments below initialize() or the viewer will not appear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min prior value 0.003448154849406748\n",
      "Max prior value 0.08234687671048904\n"
     ]
    }
   ],
   "source": [
    "# After that, we map a list of values to the Allen Atlas volume\n",
    "# Once this cell is run, click on the viewer to see the update\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import vedo\n",
    "from iblviewer import utils\n",
    "\n",
    "\n",
    "# Data given by Berk Gerçek, International Brain Laboratory\n",
    "def process_df(controller, file_path=None, aggregator='median', grouper='acronym'):\n",
    "    \"\"\"\n",
    "    Process priors data and get color map and scalar values\n",
    "    \"\"\"\n",
    "    if file_path is None:\n",
    "        test_data = './stimonR_top10_rawpoints.p'\n",
    "        file_path = str(utils.EXAMPLES_DATA_FOLDER.joinpath(test_data))\n",
    "    \n",
    "    df = np.load(file_path, allow_pickle=True)\n",
    "    \n",
    "    # For testing data given by Guido\n",
    "    # df['r_over_chance'] = df['r_prior'] - df['r_prior_null']\n",
    "    # filtered_df = df.groupby('region').median()['r_over_chance']\n",
    "    \n",
    "    raw_df = df['rawpoints']\n",
    "    filtered_df = raw_df.groupby(grouper).agg({'value': aggregator})\n",
    "    filtered_df.dropna(inplace=True)\n",
    "    min_value = float(np.amin(filtered_df, axis=0).to_numpy()[0])\n",
    "    max_value = float(np.amax(filtered_df, axis=0).to_numpy()[0])\n",
    "    print('Min prior value ' + str(min_value))\n",
    "    print('Max prior value ' + str(max_value))\n",
    "    \n",
    "    scalars_map = {}\n",
    "    \n",
    "    # This code is to be modified if you have split data for left and right hemispheres\n",
    "    # The concept is pretty simple: scalars_map is a 1D list that maps to brain regions.\n",
    "    # With the lateralized brain mapping, the standard region id in Allen CCF is negated\n",
    "    # on the right hemisphere. \n",
    "    # Currently this code uses standard acronym lookup, which yields a region on both\n",
    "    # hemispheres. The value you assign to an acronym will thus be mirrored.\n",
    "\n",
    "    # Or for i in range(0, len(df)): which preserves data types\n",
    "    for acronym, row in filtered_df.iterrows():\n",
    "        value = row.iloc[0]\n",
    "        if value is None:\n",
    "            continue\n",
    "        region_ids, row_ids = controller.model.get_region_and_row_id(acronym)\n",
    "        if region_ids is None:\n",
    "            print('Acronym', acronym, 'was not found in Atlas')\n",
    "            continue\n",
    "        for r_id in range(len(region_ids)):\n",
    "            region_id = region_ids[r_id]\n",
    "            row_id = row_ids[r_id]\n",
    "            if region_id is None:\n",
    "                print('Error, could not find acronym (ignoring it)', acronym)\n",
    "                continue\n",
    "            if row_id == 0: #or value.isnull().values.any():\n",
    "                # We ignore void acronym and nan values\n",
    "                continue\n",
    "            scalars_map[int(row_id)] = value\n",
    "    return scalars_map\n",
    "    \n",
    "def get_color_map(controller, scalar_map, color_map_func='viridis', \n",
    "                    nan_color=[0.0, 0.0, 0.0], nan_alpha=0.0, seed=None):\n",
    "    \"\"\"\n",
    "    Generate a color map with the scalar map.\n",
    "    Simply put, we assign colors to the values.\n",
    "    \"\"\"\n",
    "    if seed is not None:\n",
    "        random.seed(seed)\n",
    "    rgb = []\n",
    "    alpha = []\n",
    "    for r_id in range(controller.model.atlas.regions.id.size):\n",
    "        rand_val = np.random.uniform(0, 0.35)\n",
    "        rgb.append([r_id, np.array([rand_val]*3) + nan_color])\n",
    "        a = nan_alpha if r_id > 0 else 0.0\n",
    "        alpha.append([r_id, a])\n",
    "    \n",
    "    values = sorted(scalar_map.values())\n",
    "\n",
    "    min_p = min(values)\n",
    "    max_p = max(values)\n",
    "    rng_p = max_p - min_p\n",
    "    #cmap = vedo.colorMap(values, cmap_name, min_p, max_p)\n",
    "    for row_id in scalar_map:\n",
    "        value = scalar_map[row_id]\n",
    "        if seed is not None and seed > 0:\n",
    "            value = value + random.random() * rng_p / 2\n",
    "        #rgb[row_id] = [row_id, list(vedo.colorMap(value, cmap_name, min_p, max_p))]\n",
    "        if isinstance(color_map_func, str):\n",
    "            rgb[row_id][1] = list(vedo.colorMap(value, color_map_func, min_p, max_p))\n",
    "        else:\n",
    "            # Here we assume you provided a function that is called with these values\n",
    "            rgb[row_id][1] = color_map_func(value, min_p, max_p)\n",
    "\n",
    "        alpha[row_id] = [row_id, 1.0]\n",
    "    return rgb, alpha\n",
    "    \n",
    "def load_priors(controller, file_path=None, aggregator='median', \n",
    "                color_map_func='viridis', nan_color=[0.65, 0.65, 0.65], nan_alpha=0.8):\n",
    "    \"\"\"\n",
    "    Load priors into the viewer, faking a time series from there\n",
    "    \"\"\"\n",
    "    scalar_map = process_df(controller, file_path=file_path, aggregator=aggregator)\n",
    "    rgb_map, alpha_map = get_color_map(controller, scalar_map, color_map_func, nan_color, nan_alpha)\n",
    "    controller.add_transfer_function(scalar_map, rgb_map, alpha_map, color_map_func, make_current=False)\n",
    "\n",
    "\n",
    "load_priors(controller)\n",
    "controller.next_time_series()\n",
    "# Simple interaction example, slicing the brain on two axes\n",
    "controller.update_px_slicer(value=3000)\n",
    "controller.update_pz_slicer(value=4000)\n",
    "# Now click on the viewer and you will see the update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:iblenv] *",
   "language": "python",
   "name": "conda-env-iblenv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
